# CTM-AbsoluteZero

Un framework auto-didactique combinant Continuous Thought Machine (CTM) et le paradigme Absolute Zero Reasoner avec simulation quantique lÃ©gÃ¨re.

## ğŸŒŸ CaractÃ©ristiques

- **Architecture Proposer/Solver**: Un LLM gÃ©nÃ¨re des tÃ¢ches adaptatives, le CTM les rÃ©sout
- **SystÃ¨me de rÃ©compense multi-composantes**: Performance, faisabilitÃ©, nouveautÃ© et progression
- **Transfert inter-domaines**: Partage des connaissances entre diffÃ©rents types de tÃ¢ches
- **Simulation quantique lÃ©gÃ¨re**: Algorithmes VQE, Grover, QFT optimisÃ©s pour GPU standard
- **Ã‰volution par phases**: Exploration â†’ SpÃ©cialisation â†’ Transfert â†’ Raffinement

## ğŸ“‚ Structure du projet
```
CTM-AbsoluteZero/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ctm_az_agent.py       # Agent principal et boucle d'entraÃ®nement
â”‚   â”œâ”€â”€ rewards/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ novelty.py        # DÃ©tection de nouveautÃ© sÃ©mantique
â”‚   â”‚   â”œâ”€â”€ progress.py       # Surveillance des compÃ©tences pyramidales
â”‚   â”‚   â””â”€â”€ composite.py      # SystÃ¨me de rÃ©compense composite
â”‚   â”œâ”€â”€ transfer/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ adapter.py        # Transfert de connaissances inter-domaines
â”‚   â”‚   â””â”€â”€ phase.py          # ContrÃ´leur de phase d'entraÃ®nement
â”‚   â””â”€â”€ ctm/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ interface.py      # Interface CTM principale
â”‚       â”œâ”€â”€ maze_solver.py    # RÃ©solveur de labyrinthe
â”‚       â”œâ”€â”€ image_classifier.py # Classificateur d'images
â”‚       â”œâ”€â”€ sorter.py         # Module de tri
â”‚       â””â”€â”€ quantum_sim.py    # Simulateur quantique lÃ©ger
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ default.yaml          # Configuration par dÃ©faut
â”‚   â””â”€â”€ quantum.yaml          # Configuration spÃ©cifique quantique
â””â”€â”€ examples/
    â”œâ”€â”€ basic_training.py     # Exemple d'entraÃ®nement de base
    â””â”€â”€ quantum_tasks.py      # Exemple de tÃ¢ches quantiques
```

## ğŸš€ Installation

```bash
git clone https://github.com/your-username/CTM-AbsoluteZero.git
cd CTM-AbsoluteZero
pip install -r requirements.txt
```

## ğŸ”§ Utilisation

### EntraÃ®nement de base

```python
from src.ctm_az_agent import CTM_AbsoluteZero_Agent

# Initialiser l'agent
agent = CTM_AbsoluteZero_Agent(
    ctm_solver_config={"model_path": "path/to/ctm/checkpoint"},
    proposer_llm_name="mistralai/Mistral-7B-Instruct-v0.1"
)

# ExÃ©cuter une Ã©tape d'auto-apprentissage
reward, task = agent.run_self_play_step("maze", "GÃ©nÃ©rer un labyrinthe modÃ©rÃ©ment complexe")
print(f"TÃ¢che: {task}, RÃ©compense: {reward:.3f}")

# ExÃ©cuter la boucle complÃ¨te d'entraÃ®nement
agent.train(steps=10000, domains=["maze", "sorting", "quantum"])
```

### Configuration personnalisÃ©e

```python
import yaml

# Charger une configuration personnalisÃ©e
with open("configs/quantum.yaml", "r") as f:
    config = yaml.safe_load(f)

agent = CTM_AbsoluteZero_Agent(
    ctm_solver_config=config["ctm"],
    az_hyperparams=config["absolute_zero"],
    ppo_config_dict=config["ppo"]
)
```

## ğŸ“˜ Composants principaux

### CTM_AbsoluteZero_Agent
Classe principale intÃ©grant le Proposer (LLM) et le Solver (CTM), gÃ©rant la boucle d'auto-apprentissage et les mises Ã  jour PPO.

```python
# Exemple d'utilisation du gÃ©nÃ©rateur de tÃ¢ches
task = agent.propose_task("quantum", "PrivilÃ©gier les algorithmes QFT")
print(task)
# {'type': 'quantum_task', 'params': {'algorithm': 'qft', 'num_qubits': 6, 'noise_level': 0.01, 'circuit_depth': 5}}
```

### SemanticNoveltyTracker
DÃ©tecte les tÃ¢ches vÃ©ritablement nouvelles en utilisant des empreintes de paramÃ¨tres et des similaritÃ©s cosinus.

```python
from src.rewards.novelty import SemanticNoveltyTracker

tracker = SemanticNoveltyTracker()
task1 = {"type": "maze", "params": {"size_x": 10, "size_y": 10, "complexity": 0.5}}
task2 = {"type": "maze", "params": {"size_x": 11, "size_y": 10, "complexity": 0.52}}
task3 = {"type": "maze", "params": {"size_x": 20, "size_y": 20, "complexity": 0.9}}

print(tracker.calculate_novelty(task1))  # 1.0 (premiÃ¨re tÃ¢che)
print(tracker.calculate_novelty(task2))  # 0.0 (similaire Ã  task1)
print(tracker.calculate_novelty(task3))  # 1.0 (significativement diffÃ©rent)
```

### SkillPyramid
Suit la progression hiÃ©rarchique des compÃ©tences dans diffÃ©rents domaines et niveaux de difficultÃ©.

```python
from src.rewards.progress import SkillPyramid

pyramid = SkillPyramid()
scores = [0.5, 0.55, 0.6, 0.65, 0.7]
task = {"type": "quantum", "params": {"num_qubits": 4, "algorithm": "vqe"}}

for score in scores:
    progress = pyramid.record_and_assess(task, score)
    print(f"Score: {score}, ProgrÃ¨s: {progress:.3f}")
```

### NeuralTransferAdapter
Permet le transfert de connaissances entre domaines en modifiant les paramÃ¨tres des tÃ¢ches.

```python
from src.transfer.adapter import NeuralTransferAdapter

adapter = NeuralTransferAdapter(["maze", "quantum", "sorting"])
domain_perf = {
    "sorting": {"avg": 0.8, "trend": 0.1, "var": 0.02},
    "quantum": {"avg": 0.6, "trend": 0.05, "var": 0.04}
}

task = {"type": "rl", "params": {"env_id": "CartPole", "max_episode_steps": 200}}
modified_task = adapter.transfer_parameters("rl", task, domain_perf)
print(modified_task)
# {'type': 'rl', 'params': {'env_id': 'CartPole', 'max_episode_steps': 440}}
```

### PhaseController
GÃ¨re les transitions entre phases d'entraÃ®nement et ajuste les poids des rÃ©compenses en consÃ©quence.

```python
from src.transfer.phase import PhaseController

controller = PhaseController()
print(controller.current_phase)  # 'exploration'
print(controller.get_weights())  # {'solve': 0.4, 'propose': 0.2, 'novelty': 0.3, 'progress': 0.1}

# Simuler une transition de phase
metrics = {'success_rate': [0.7, 0.68, 0.72], 'cross_domain_corr': 0.3}
controller.update_phase(metrics)
print(controller.current_phase)  # 'specialization'
```

## ğŸ§ª Simulateur Quantique

Le module de simulation quantique lÃ©gÃ¨re permet de tester des algorithmes quantiques sans matÃ©riel spÃ©cialisÃ©.

```python
from src.ctm.quantum_sim import QuantumSimulator

simulator = QuantumSimulator()
result = simulator.run({
    'algorithm': 'grover', 
    'num_qubits': 5, 
    'noise_level': 0.01,
    'circuit_depth': 4
})

print(f"Score: {result['main_score']}, FidÃ©litÃ©: {result['circuit_fidelity']}")
```

## ğŸ“Š Performances

Le framework a Ã©tÃ© testÃ© sur divers domaines avec les rÃ©sultats suivants:

| Phase | DurÃ©e (Ã©tapes) | Taux de rÃ©ussite moyen | CorrÃ©lation inter-domaines |
|-------|----------------|------------------------|----------------------------|
| Exploration | 0-5000 | 48.2% | 0.31 |
| SpÃ©cialisation | 5000-20000 | 67.5% | 0.58 |
| Transfert | 20000-35000 | 72.3% | 0.77 |
| Raffinement | 35000-50000 | 84.1% | 0.85 |

## ğŸ“œ Licence

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ¤ Contribution

Les contributions sont les bienvenues! N'hÃ©sitez pas Ã  ouvrir une issue ou soumettre une pull request.

1. Forkez le projet
2. CrÃ©ez votre branche de fonctionnalitÃ© (`git checkout -b feature/amazing-feature`)
3. Committez vos changements (`git commit -m 'Add some amazing feature'`)
4. Poussez vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrez une Pull Request

## ğŸ“ Contact

Votre Nom - @twitter_handle - email@example.com

URL du projet: https://github.com/your-username/CTM-AbsoluteZero

<p align="center">
  <img src="https://via.placeholder.com/150?text=CTM-AZ" alt="CTM-AbsoluteZero Logo"/>
</p>
<p align="center">
  <i>Construisez des agents auto-didactiques avec transfert inter-domaines et simulation quantique lÃ©gÃ¨re.</i>
</p>